<!DOCTYPE html>
<html lang="en">

  <!-- Head -->
  <head>
<meta http-equiv="Content-Type" content="text/html; charset=UTF-8">    <!-- Metadata, OpenGraph and Schema.org -->
    
    <!-- Website verification -->
    <meta name="google-site-verification" content="">
<!-- Avoid warning on Google Chrome
        Error with Permissions-Policy header: Origin trial controlled feature not enabled: 'interest-cohort'.
        see https://stackoverflow.com/a/75119417
    -->
    <meta http-equiv="Permissions-Policy" content="interest-cohort=()">

    <!-- Standard metadata -->
    <meta charset="utf-8">
    <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">
    <meta http-equiv="X-UA-Compatible" content="IE=edge">
    <title>publications | Epsit  Bhardwaj</title>
    <meta name="author" content="Epsit  Bhardwaj">
    <meta name="description" content="publications">


    <!-- Bootstrap & MDB -->
    <link href="https://cdn.jsdelivr.net/npm/bootstrap@4.6.1/dist/css/bootstrap.min.css" rel="stylesheet" integrity="sha256-DF7Zhf293AJxJNTmh5zhoYYIMs2oXitRfBjY+9L//AY=" crossorigin="anonymous">
    <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/mdbootstrap@4.20.0/css/mdb.min.css" integrity="sha256-jpjYvU3G3N6nrrBwXJoVEYI/0zw8htfFnhT9ljN3JJw=" crossorigin="anonymous">

    <!-- Bootstrap Table -->
    <link defer rel="stylesheet" href="https://unpkg.com/bootstrap-table@1.21.4/dist/bootstrap-table.min.css">

    <!-- Fonts & Icons -->
    <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/@fortawesome/fontawesome-free@5.15.4/css/all.min.css" integrity="sha256-mUZM63G8m73Mcidfrv5E+Y61y7a12O5mW4ezU3bxqW4=" crossorigin="anonymous">
    <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/academicons@1.9.1/css/academicons.min.css" integrity="sha256-i1+4qU2G2860dGGIOJscdC30s9beBXjFfzjWLjBRsBg=" crossorigin="anonymous">
    <link rel="stylesheet" type="text/css" href="https://fonts.googleapis.com/css?family=Roboto:300,400,500,700|Roboto+Slab:100,300,400,500,700|Material+Icons">

    <!-- Code Syntax Highlighting -->
    <link rel="stylesheet" href="https://cdn.jsdelivr.net/gh/jwarby/jekyll-pygments-themes@master/github.css" media="" id="highlight_theme_light">

    

    <!-- Styles -->
    
    <link rel="shortcut icon" href="/assets/img/favicon.ico">
    
    <link rel="stylesheet" href="/assets/css/main.css">
    <link rel="canonical" href="https://epsit03.github.io/publications/">

    <!-- Dark Mode -->
    
    <link rel="stylesheet" href="https://cdn.jsdelivr.net/gh/jwarby/jekyll-pygments-themes@master/native.css" media="none" id="highlight_theme_dark">

    <script src="/assets/js/theme.js"></script>
    <script src="/assets/js/dark_mode.js"></script>
    

  </head>

  <!-- Body -->
  <body class="fixed-top-nav ">

    <!-- Header -->
    <header>

      <!-- Nav Bar -->
      <nav id="navbar" class="navbar navbar-light navbar-expand-sm fixed-top">
        <div class="container">
          <a class="navbar-brand title font-weight-lighter" href="/"><span class="font-weight-bold">Epsit </span>Bhardwaj</a>
          <!-- Navbar Toggle -->
          <button class="navbar-toggler collapsed ml-auto" type="button" data-toggle="collapse" data-target="#navbarNav" aria-controls="navbarNav" aria-expanded="false" aria-label="Toggle navigation">
            <span class="sr-only">Toggle navigation</span>
            <span class="icon-bar top-bar"></span>
            <span class="icon-bar middle-bar"></span>
            <span class="icon-bar bottom-bar"></span>
          </button>

          <div class="collapse navbar-collapse text-right" id="navbarNav">
            <ul class="navbar-nav ml-auto flex-nowrap">

              <!-- About -->
              <li class="nav-item ">
                <a class="nav-link" href="/">about</a>
              </li>
              
              <!-- Blog -->
              <li class="nav-item ">
                <a class="nav-link" href="/blog/">blog</a>
              </li>

              <!-- Other pages -->
              <li class="nav-item active">
                <a class="nav-link" href="/publications/">publications<span class="sr-only">(current)</span></a>
              </li>
              <li class="nav-item ">
                <a class="nav-link" href="/repositories/">codes</a>
              </li>
              <li class="nav-item ">
                <a class="nav-link" href="/cv/">cv</a>
              </li>
              <li class="nav-item ">
                <a class="nav-link" href="/talks/">talks</a>
              </li>

              <!-- Toogle theme mode -->
              <li class="toggle-container">
                <button id="light-toggle" title="Change theme">
                  <i class="fas fa-moon"></i>
                  <i class="fas fa-sun"></i>
                </button>
              </li>
            </ul>
          </div>
        </div>
      </nav>

      <!-- Scrolling Progress Bar -->
      <progress id="progress" value="0">
        <div class="progress-container">
          <span class="progress-bar"></span>
        </div>
      </progress>
    </header>


    <!-- Content -->
    <div class="container mt-5">
      
        <!-- publication.html -->

<div class="post">

    <header class="post-header">
        <h1 class="post-title">publications</h1>
        <p class="post-description"><span class="star">*</span> denotes equal contribution</p>
        <!--<p class="post-description"> </p>-->
    </header>

    <article>
        <!-- _pages/publications.md -->

<p>An up-to-date list is available on <a href="https://scholar.google.com/citations?user=MXqo0_UAAAAJ" target="_blank" rel="noopener noreferrer">Google Scholar</a>.</p>

<div class="publications">
  <h2 class="year">2023</h2>
  <ol class="bibliography"><li>
<!-- _layouts/bib.html -->
<div class="row">
  <div class="col-sm-2 preview">
<img id="medhaltpng" class="preview z-depth-1 rounded myImg" src="/assets/img/publication_preview/medhalt.png"><div id="medhaltpng-modal" class="modal2">
      <span class="closeimg" onclick="document.getElementById('medhaltpng-modal').style.display='none'">×</span>
      <div class="myCaption"></div>
      <img class="modal-content2" id="medhaltpng-modal-img">
    </div>
    <script>
      // Get the modal
      var modal = document.getElementById("medhaltpng-modal");
      // Get the image and insert it inside the modal - use its "alt" text as a caption
      var img = document.getElementById('medhaltpng');
      var modalImg = document.getElementById("medhaltpng-modal-img");
      var captionText = modal.getElementsByTagName('div')[0];
      img.onclick = function () {
        modal.style.display = "block";
        modalImg.src = this.src;
        captionText.innerHTML = "";
      }
      // Get the <span> element that closes the modal
      var span = modal.getElementsByTagName('span')[0];
      // When the user clicks on <span> (x), close the modal
      span.onclick = function () {
        modal.style.display = "none";
      }
      modal.onclick = function () {
        modal.style.display = "none";
      }
    </script>
</div>

  <!-- Entry bib key -->
  <div id="MedHALT" class="col-sm-8 col-md-9">
    <!-- Title -->
    <div class="title">Med-HALT: Medical Domain Hallucination Test for Large Language Models</div>
    <!-- Author -->
    <div class="author">
      

      Ankit Pal, <a href="https://scholar.google.com/citations?user=eWwEqToAAAAJ&amp;hl=en" rel="external nofollow noopener" target="_blank">Logesh Kumar Umapathi</a>, and <a href="https://scholar.google.com/citations?user=znWv6tUAAAAJ&amp;hl=en" rel="external nofollow noopener" target="_blank">Malaikannan Sankarasubbu</a>
</div>

    <!-- Journal/Book title and date -->
    
    
    <div class="periodical">
      <em>Empirical Methods in Natural Language Processing(Conll)</em>, 2023
    </div>
    <div class="periodical">
      
    </div>

    <!-- Links/Buttons -->
    <div class="links">
      <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a>
      <a href="https://arxiv.org/abs/2307.15343" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">URL</a>
      <a href="https://arxiv.org/pdf/2307.15343.pdf" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">PDF</a>
      <a href="https://github.com/medhalt/medhalt" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">Code</a>
      <a href="/assets/pdf/" class="btn btn-sm z-depth-0" role="button">Slides</a>
    </div>
    
    <div class="badges">
    </div>

    <!-- Hidden abstract block -->
    <div class="abstract hidden">
      <p>This research paper focuses on the challenges posed by hallucinations in large language models (LLMs), particularly in the context of the medical domain. Hallucination, wherein these models generate plausible yet unverified or incorrect information, can have serious consequences in healthcare applications. We propose a new benchmark and dataset, Med-HALT (Medical Domain Hallucination Test), designed specifically to evaluate and reduce hallucinations. Med-HALT provides a diverse multinational dataset derived from medical examinations across various countries and includes multiple innovative testing modalities. Med-HALT includes two categories of tests reasoning and memory-based hallucination tests, designed to assess LLMs’s problem-solving and information retrieval abilities. Our study evaluated leading LLMs, including Text Davinci, GPT-3.5, LlaMa-2, MPT, and Falcon, revealing significant differences in their performance. The paper provides detailed insights into the dataset, promoting transparency and reproducibility. Through this work, we aim to contribute to the development of safer and more reliable language models in healthcare. Our benchmark can be found at medhalt.github.io</p>
    </div>
  </div>
</div>
</li></ol>

  <h2 class="year">2022</h2>
  <ol class="bibliography">
<li>
<!-- _layouts/bib.html -->
<div class="row">
  <div class="col-sm-2 abbr"><abbr class="badge">NeurIPS</abbr></div>

  <!-- Entry bib key -->
  <div id="Clift" class="col-sm-8 col-md-9">
    <!-- Title -->
    <div class="title">CLIFT: Analysing Natural Distribution Shift on Question Answering Models in Clinical Domain</div>
    <!-- Author -->
    <div class="author">
      

      Ankit Pal</div>

    <!-- Journal/Book title and date -->
    
    
    <div class="periodical">
      <em>NeurIPS-2022: Robustness in Sequence Modeling</em>
    </div>
    <div class="periodical">
      
    </div>

    <!-- Links/Buttons -->
    <div class="links">
      <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a>
      <a href="https://nips.cc/virtual/2022/58229" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">URL</a>
      <a href="https://openreview.net/pdf?id=9PQFROOfqm" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">PDF</a>
      <a href="https://nips.cc/media/PosterPDFs/NeurIPS%202022/58229.png?t=1668359616.0178533" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">Poster</a>
    </div>
    
    <div class="badges">
    </div>

    <!-- Hidden abstract block -->
    <div class="abstract hidden">
      <p>This paper introduces a new testbed CLIFT (Clinical Shift) for the clinical domain Question Answering task. The testbed includes 7.5k high-quality questionanswering samples to provide a diverse and reliable benchmark. We performed a comprehensive experimental study and evaluated several QA deep-learning models under the proposed testbed. Despite impressive results on the original test set, the performance degrades when applied to new test sets, which shows the distribution shift. Our findings emphasize the need for and the potential for increasing the robustness of clinical domain models under distributional shifts. The testbed offers one way to track progress in that direction. It also highlights the necessity of adopting evaluation metrics that consider robustness to natural distribution shifts. We plan to expand the corpus by adding more samples and model results. The full paper and the updated benchmark are available at openlifescience-ai.github.io/clift</p>
    </div>
  </div>
</div>
</li>
<li>
<!-- _layouts/bib.html -->
<div class="row">
  <div class="col-sm-2 preview">
<img id="medmcqapng" class="preview z-depth-1 rounded myImg" src="/assets/img/publication_preview/medmcqa.png"><div id="medmcqapng-modal" class="modal2">
      <span class="closeimg" onclick="document.getElementById('medmcqapng-modal').style.display='none'">×</span>
      <div class="myCaption"></div>
      <img class="modal-content2" id="medmcqapng-modal-img">
    </div>
    <script>
      // Get the modal
      var modal = document.getElementById("medmcqapng-modal");
      // Get the image and insert it inside the modal - use its "alt" text as a caption
      var img = document.getElementById('medmcqapng');
      var modalImg = document.getElementById("medmcqapng-modal-img");
      var captionText = modal.getElementsByTagName('div')[0];
      img.onclick = function () {
        modal.style.display = "block";
        modalImg.src = this.src;
        captionText.innerHTML = "";
      }
      // Get the <span> element that closes the modal
      var span = modal.getElementsByTagName('span')[0];
      // When the user clicks on <span> (x), close the modal
      span.onclick = function () {
        modal.style.display = "none";
      }
      modal.onclick = function () {
        modal.style.display = "none";
      }
    </script>
</div>

  <!-- Entry bib key -->
  <div id="MedMCQA" class="col-sm-8 col-md-9">
    <!-- Title -->
    <div class="title">MedMCQA : A Large-scale Multi-Subject Multi-Choice Dataset for Medical domain Question Answering</div>
    <!-- Author -->
    <div class="author">
      

      Ankit Pal, <a href="https://scholar.google.com/citations?user=eWwEqToAAAAJ&amp;hl=en" rel="external nofollow noopener" target="_blank">Logesh Kumar Umapathi</a>, and <a href="https://scholar.google.com/citations?user=znWv6tUAAAAJ&amp;hl=en" rel="external nofollow noopener" target="_blank">Malaikannan Sankarasubbu</a>
</div>

    <!-- Journal/Book title and date -->
    
    
    <div class="periodical">
      <em>Proceedings of Machine Learning Research(PMLR)</em>, 2022
    </div>
    <div class="periodical">
      
    </div>

    <!-- Links/Buttons -->
    <div class="links">
      <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a>
      <a href="https://proceedings.mlr.press/v174/pal22a.html" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">URL</a>
      <a href="https://proceedings.mlr.press/v174/pal22a/pal22a.pdf" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">PDF</a>
      <a href="https://github.com/medmcqa/medmcqa" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">Code</a>
      <a href="https://github.com/monk1337/ResearchSlides/blob/main/MedMCQA_paper/presentation_slides.pdf" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">Slides</a>
    </div>
    
    <div class="badges">
    </div>

    <!-- Hidden abstract block -->
    <div class="abstract hidden">
      <p>This paper introduces MedMCQA, a new large-scale, Multiple-Choice Question Answering (MCQA) dataset designed to address real-world medical entrance exam questions. More than 194k high-quality AIIMS &amp; NEET PG entrance exam MCQs covering 2.4k healthcare topics and 21 medical subjects are collected with an average token length of 12.77 and high topical diversity. Each sample contains a question, correct answer(s), and other options which requires a deeper language understanding as it tests the 10+ reasoning abilities of a model across a wide range of medical subjects &amp; topics. A detailed explanation of the solution, along with the above information, is provided in this study.</p>
    </div>
  </div>
</div>
</li>
<li>
<!-- _layouts/bib.html -->
<div class="row">
  <div class="col-sm-2 preview">
<img id="fedlearnpng" class="preview z-depth-1 rounded myImg" src="/assets/img/publication_preview/fedlearn.png"><div id="fedlearnpng-modal" class="modal2">
      <span class="closeimg" onclick="document.getElementById('fedlearnpng-modal').style.display='none'">×</span>
      <div class="myCaption"></div>
      <img class="modal-content2" id="fedlearnpng-modal-img">
    </div>
    <script>
      // Get the modal
      var modal = document.getElementById("fedlearnpng-modal");
      // Get the image and insert it inside the modal - use its "alt" text as a caption
      var img = document.getElementById('fedlearnpng');
      var modalImg = document.getElementById("fedlearnpng-modal-img");
      var captionText = modal.getElementsByTagName('div')[0];
      img.onclick = function () {
        modal.style.display = "block";
        modalImg.src = this.src;
        captionText.innerHTML = "";
      }
      // Get the <span> element that closes the modal
      var span = modal.getElementsByTagName('span')[0];
      // When the user clicks on <span> (x), close the modal
      span.onclick = function () {
        modal.style.display = "none";
      }
      modal.onclick = function () {
        modal.style.display = "none";
      }
    </script>
</div>

  <!-- Entry bib key -->
  <div id="FedLearn" class="col-sm-8 col-md-9">
    <!-- Title -->
    <div class="title">Federated learning for healthcare domain - pipeline, applications and challenges</div>
    <!-- Author -->
    <div class="author">
      

      <a href="https://madhura12gj.github.io/MadhuraJoshi/" rel="external nofollow noopener" target="_blank">Madhura Joshi*</a>, Ankit Pal*, and <a href="https://scholar.google.com/citations?user=znWv6tUAAAAJ&amp;hl=en" rel="external nofollow noopener" target="_blank">Malaikannan Sankarasubbu</a>
</div>

    <!-- Journal/Book title and date -->
    
    
    <div class="periodical">
      <em>ACM Transactions on Computing for Healthcare</em>, 2022
    </div>
    <div class="periodical">
      
    </div>

    <!-- Links/Buttons -->
    <div class="links">
      <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a>
      <a href="https://dl.acm.org/doi/10.1145/3533708" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">URL</a>
      <a href="https://dl.acm.org/doi/pdf/10.1145/3533708" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">PDF</a>
      <a href="https://github.com/monk1337/ResearchSlides/blob/main/Federated_learning_paper/presentation_slides.pdf" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">Slides</a>
    </div>
    
    <div class="badges">
    </div>

    <!-- Hidden abstract block -->
    <div class="abstract hidden">
      <p>Federated learning is the process of developing machine learning models over datasets distributed across data centers such as hospitals, clinical research labs, and mobile devices while preventing data leakage. This survey examines previous research and studies on federated learning in the healthcare sector across a range of use cases and applications. Our survey shows what challenges, methods, and applications a practitioner should be aware of in the topic of federated learning. This paper aims to lay out existing research and list the possibilities of federated learning for healthcare industries.</p>
    </div>
  </div>
</div>
</li>
<li>
<!-- _layouts/bib.html -->
<div class="row">
  <div class="col-sm-2 abbr"><abbr class="badge">EMNLP</abbr></div>

  <!-- Entry bib key -->
  <div id="DeepParliament" class="col-sm-8 col-md-9">
    <!-- Title -->
    <div class="title">DeepParliament: A Legal domain Benchmark &amp; Dataset for Parliament Bills Prediction</div>
    <!-- Author -->
    <div class="author">
      

      Ankit Pal</div>

    <!-- Journal/Book title and date -->
    
    
    <div class="periodical">
      <em>Empirical Methods in Natural Language Processing(UM-IoS)</em>, 2022
    </div>
    <div class="periodical">
      
    </div>

    <!-- Links/Buttons -->
    <div class="links">
      <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a>
      <a href="https://aclanthology.org/2022.umios-1.8/" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">URL</a>
      <a href="https://aclanthology.org/2022.umios-1.8.pdf" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">PDF</a>
      <a href="https://github.com/monk1337/DeepParliament/tree/main" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">Code</a>
    </div>
    
    <div class="badges">
    </div>

    <!-- Hidden abstract block -->
    <div class="abstract hidden">
      <p>This paper introduces DeepParliament, a legal domain Benchmark Dataset that gathers bill documents and metadata and performs various bill status classification tasks. The proposed dataset text covers a broad range of bills from 1986 to the present and contains richer information on parliament bill content. Data collection, detailed statistics and analyses are provided in the paper. Moreover, we experimented with different types of models ranging from RNN to pretrained and reported the results. We are proposing two new benchmarks: Binary and Multi-Class Bill Status classification. Models developed for bill documents and relevant supportive tasks may assist Members of Parliament (MPs), presidents, and other legal practitioners. It will help review or prioritise bills, thus speeding up the billing process, improving the quality of decisions and reducing the time consumption in both houses. Considering that the foundation of the country”s democracy is Parliament and state legislatures, we anticipate that our research will be an essential addition to the Legal NLP community. This work will be the first to present a Parliament bill prediction task. In order to improve the accessibility of legal AI resources and promote reproducibility, we have made our code and dataset publicly accessible at github.com/monk1337/DeepParliament.</p>
    </div>
  </div>
</div>
</li>
</ol>

  <h2 class="year">2021</h2>
  <ol class="bibliography"><li>
<!-- _layouts/bib.html -->
<div class="row">
  <div class="col-sm-2 preview">
<img id="coughpng" class="preview z-depth-1 rounded myImg" src="/assets/img/publication_preview/cough.png"><div id="coughpng-modal" class="modal2">
      <span class="closeimg" onclick="document.getElementById('coughpng-modal').style.display='none'">×</span>
      <div class="myCaption"></div>
      <img class="modal-content2" id="coughpng-modal-img">
    </div>
    <script>
      // Get the modal
      var modal = document.getElementById("coughpng-modal");
      // Get the image and insert it inside the modal - use its "alt" text as a caption
      var img = document.getElementById('coughpng');
      var modalImg = document.getElementById("coughpng-modal-img");
      var captionText = modal.getElementsByTagName('div')[0];
      img.onclick = function () {
        modal.style.display = "block";
        modalImg.src = this.src;
        captionText.innerHTML = "";
      }
      // Get the <span> element that closes the modal
      var span = modal.getElementsByTagName('span')[0];
      // When the user clicks on <span> (x), close the modal
      span.onclick = function () {
        modal.style.display = "none";
      }
      modal.onclick = function () {
        modal.style.display = "none";
      }
    </script>
</div>

  <!-- Entry bib key -->
  <div id="Cough" class="col-sm-8 col-md-9">
    <!-- Title -->
    <div class="title">Pay Attention to the cough: Early Diagnosis of COVID-19 using Interpretable Symptoms Embeddings with Cough Sound Signal Processing</div>
    <!-- Author -->
    <div class="author">
      

      Ankit Pal, and <a href="https://scholar.google.com/citations?user=znWv6tUAAAAJ&amp;hl=en" rel="external nofollow noopener" target="_blank">Malaikannan Sankarasubbu</a>
</div>

    <!-- Journal/Book title and date -->
    
    
    <div class="periodical">
      <em>Proceedings of the 36th Annual ACM Symposium on Applied Computing</em>, 2021
    </div>
    <div class="periodical">
      
    </div>

    <!-- Links/Buttons -->
    <div class="links">
      <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a>
      <a href="https://dl.acm.org/doi/10.1145/3412841.3441943" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">URL</a>
      <a href="https://dl.acm.org/doi/pdf/10.1145/3412841.3441943" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">PDF</a>
      <a href="https://github.com/coughresearch/Cough-signal-processing" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">Code</a>
      <a href="https://github.com/monk1337/ResearchSlides/blob/main/Cough_paper/presentation_slides.pdf" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">Slides</a>
      <a href="https://coughresearch.github.io/" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">Website</a>
    </div>
    
    <div class="badges">
    </div>

    <!-- Hidden abstract block -->
    <div class="abstract hidden">
      <p>COVID-19 (coronavirus disease 2019) pandemic caused by SARS-CoV-2 has led to a treacherous and devastating catastrophe for humanity. At the time of writing, no specific antivirus drugs or vaccines are recommended to control infection transmission and spread. The current diagnosis of COVID-19 is done by Reverse-Transcription Polymer Chain Reaction (RT-PCR) testing. However, this method is expensive, time-consuming, and not easily available in straitened regions. An interpretable and COVID-19 diagnosis AI framework is devised and developed based on the cough sounds features and symptoms metadata to overcome these limitations. The proposed framework’s performance was evaluated using a medical dataset containing Symptoms and Demographic data of 30000 audio segments, 328 cough sounds from 150 patients with four cough classes ( COVID-19, Asthma, Bronchitis, and Healthy). Experiments’ results show that the model captures the better and robust feature embedding to distinguish between COVID-19 patient coughs and several types of non-COVID-19 coughs with higher specificity and accuracy of 95.04 ± 0.18% and 96.83± 0.18% respectively, all the while maintaining interpretability.</p>
    </div>
  </div>
</div>
</li></ol>

  <h2 class="year">2020</h2>
  <ol class="bibliography"><li>
<!-- _layouts/bib.html -->
<div class="row">
  <div class="col-sm-2 preview">
<img id="magnetgif" class="preview z-depth-1 rounded myImg" src="/assets/img/publication_preview/magnet.gif"><div id="magnetgif-modal" class="modal2">
      <span class="closeimg" onclick="document.getElementById('magnetgif-modal').style.display='none'">×</span>
      <div class="myCaption"></div>
      <img class="modal-content2" id="magnetgif-modal-img">
    </div>
    <script>
      // Get the modal
      var modal = document.getElementById("magnetgif-modal");
      // Get the image and insert it inside the modal - use its "alt" text as a caption
      var img = document.getElementById('magnetgif');
      var modalImg = document.getElementById("magnetgif-modal-img");
      var captionText = modal.getElementsByTagName('div')[0];
      img.onclick = function () {
        modal.style.display = "block";
        modalImg.src = this.src;
        captionText.innerHTML = "";
      }
      // Get the <span> element that closes the modal
      var span = modal.getElementsByTagName('span')[0];
      // When the user clicks on <span> (x), close the modal
      span.onclick = function () {
        modal.style.display = "none";
      }
      modal.onclick = function () {
        modal.style.display = "none";
      }
    </script>
</div>

  <!-- Entry bib key -->
  <div id="Magnet" class="col-sm-8 col-md-9">
    <!-- Title -->
    <div class="title">MAGNET: Multi-Label Text Classification using Attention-based Graph Neural Network</div>
    <!-- Author -->
    <div class="author">
      

      Ankit Pal, <a href="https://scholar.google.com/citations?user=_KPtoVcAAAAJ&amp;hl=en" rel="external nofollow noopener" target="_blank">Muru Selvakumar</a>, and <a href="https://scholar.google.com/citations?user=znWv6tUAAAAJ&amp;hl=en" rel="external nofollow noopener" target="_blank">Malaikannan Sankarasubbu</a>
</div>

    <!-- Journal/Book title and date -->
    
    
    <div class="periodical">
      <em>Proceedings of the 12th International Conference on Agents and Artificial Intelligence</em>, 2020
    </div>
    <div class="periodical">
      
    </div>

    <!-- Links/Buttons -->
    <div class="links">
      <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a>
      <a href="https://doi.org/10.5220%2F0008940304940505" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">URL</a>
      <a href="https://arxiv.org/pdf/2003.11644.pdf" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">PDF</a>
      <a href="https://github.com/monk1337/ResearchSlides/blob/main/Magnet_paper/Presentation_slides.pdf" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">Slides</a>
    </div>
    
    <div class="badges">
    </div>

    <!-- Hidden abstract block -->
    <div class="abstract hidden">
      <p>In Multi-Label Text Classification (MLTC), one sample can belong to more than one class. It is observed that most MLTC tasks, there are dependencies or correlations among labels. Existing methods tend to ignore the relationship among labels. In this paper, a graph attention network-based model is proposed to capture the attentive dependency structure among the labels. The graph attention network uses a feature matrix and a correlation matrix to capture and explore the crucial dependencies between the labels and generate classifiers for the task. The generated classifiers are applied to sentence feature vectors obtained from the text feature extraction network (BiLSTM) to enable end-to-end training. Attention allows the system to assign different weights to neighbor nodes per label, thus allowing it to learn the dependencies among labels implicitly. The results of the proposed model are validated on five real-world MLTC datasets. The proposed model achieves similar or better performance compared to the previous state-of-the-art models.</p>
    </div>
  </div>
</div>
</li></ol>

  <h2 class="year">2019</h2>
  <ol class="bibliography"></ol>

  <h2 class="year">2017</h2>
  <ol class="bibliography"></ol>


</div>

    </article>

</div>
      
    </div>

    <!-- Footer -->    
    <footer class="fixed-bottom">
      <div class="container mt-0">
        © Copyright 2024 Epsit  Bhardwaj. Powered by <a href="https://jekyllrb.com/" target="_blank" rel="external nofollow noopener">Jekyll</a> with <a href="https://github.com/alshedivat/al-folio" rel="external nofollow noopener" target="_blank">al-folio</a> theme.
Last updated: March 14, 2024.
      </div>
    </footer>

    <!-- JavaScripts -->
    <!-- jQuery -->
  <script src="https://cdn.jsdelivr.net/npm/jquery@3.6.0/dist/jquery.min.js" integrity="sha256-/xUj+3OJU5yExlq6GSYGSHk7tPXikynS7ogEvDej/m4=" crossorigin="anonymous"></script>

    <!-- Bootsrap & MDB scripts -->
  <script src="https://cdn.jsdelivr.net/npm/bootstrap@4.6.1/dist/js/bootstrap.bundle.min.js" integrity="sha256-fgLAgv7fyCGopR/gBNq2iW3ZKIdqIcyshnUULC4vex8=" crossorigin="anonymous"></script>
  <script src="https://cdn.jsdelivr.net/npm/mdbootstrap@4.20.0/js/mdb.min.js" integrity="sha256-NdbiivsvWt7VYCt6hYNT3h/th9vSTL4EDWeGs5SN3DA=" crossorigin="anonymous"></script>

    <!-- Masonry & imagesLoaded -->
  <script defer src="https://cdn.jsdelivr.net/npm/masonry-layout@4.2.2/dist/masonry.pkgd.min.js" integrity="sha256-Nn1q/fx0H7SNLZMQ5Hw5JLaTRZp0yILA/FRexe19VdI=" crossorigin="anonymous"></script>
  <script defer src="https://cdn.jsdelivr.net/npm/imagesloaded@4/imagesloaded.pkgd.min.js"></script>
  <script defer src="/assets/js/masonry.js" type="text/javascript"></script>
    
  <!-- Medium Zoom JS -->
  <script defer src="https://cdn.jsdelivr.net/npm/medium-zoom@1.0.8/dist/medium-zoom.min.js" integrity="sha256-7PhEpEWEW0XXQ0k6kQrPKwuoIomz8R8IYyuU1Qew4P8=" crossorigin="anonymous"></script>
  <script defer src="/assets/js/zoom.js"></script>

  <!-- Bootstrap Table -->
  <script defer src="https://unpkg.com/bootstrap-table@1.21.4/dist/bootstrap-table.min.js"></script>

  <!-- Load Common JS -->
  <script src="/assets/js/no_defer.js"></script>
  <script defer src="/assets/js/common.js"></script>
  <script defer src="/assets/js/copy_code.js" type="text/javascript"></script>

    

    <!-- MathJax -->
  <script type="text/javascript">
    window.MathJax = {
      tex: {
        tags: 'ams'
      }
    };
  </script>
  <script defer type="text/javascript" id="MathJax-script" src="https://cdn.jsdelivr.net/npm/mathjax@3.2.0/es5/tex-mml-chtml.js"></script>
  <script defer src="https://polyfill.io/v3/polyfill.min.js?features=es6"></script>

    <!-- Global site tag (gtag.js) - Google Analytics -->
  <script async src="https://www.googletagmanager.com/gtag/js?id="></script>
  <script>
    window.dataLayer = window.dataLayer || [];
    function gtag(){ window.dataLayer.push(arguments); }
    gtag('js', new Date());
    gtag('config', '');
  </script>
    

<!-- Scrolling Progress Bar -->
<script type="text/javascript">
  /*
   * This JavaScript code has been adapted from the article 
   * https://css-tricks.com/reading-position-indicator/ authored by Pankaj Parashar, 
   * published on the website https://css-tricks.com on the 7th of May, 2014.
   * Couple of changes were made to the original code to make it compatible 
   * with the `al-foio` theme.
   */
  const progressBar = $("#progress");
  /*
   * We set up the bar after all elements are done loading.
   * In some cases, if the images in the page are larger than the intended
   * size they'll have on the page, they'll be resized via CSS to accomodate
   * the desired size. This mistake, however, breaks the computations as the
   * scroll size is computed as soon as the elements finish loading.
   * To account for this, a minimal delay was introduced before computing the
   * values.
   */
  window.onload = function () {
    setTimeout(progressBarSetup, 50);
  };
  /*
   * We set up the bar according to the browser.
   * If the browser supports the progress element we use that.
   * Otherwise, we resize the bar thru CSS styling
   */
  function progressBarSetup() {
    if ("max" in document.createElement("progress")) {
      initializeProgressElement();
      $(document).on("scroll", function() {
        progressBar.attr({ value: getCurrentScrollPosition() });
      });
      $(window).on("resize", initializeProgressElement);
    } else {
      resizeProgressBar();
      $(document).on("scroll", resizeProgressBar);
      $(window).on("resize", resizeProgressBar);
    }
  }
  /*
   * The vertical scroll position is the same as the number of pixels that
   * are hidden from view above the scrollable area. Thus, a value > 0 is
   * how much the user has scrolled from the top
   */
  function getCurrentScrollPosition() {
    return $(window).scrollTop();
  }

  function initializeProgressElement() {
    let navbarHeight = $("#navbar").outerHeight(true);
    $("body").css({ "padding-top": navbarHeight });
    $("progress-container").css({ "padding-top": navbarHeight });
    progressBar.css({ top: navbarHeight });
    progressBar.attr({
      max: getDistanceToScroll(),
      value: getCurrentScrollPosition(),
    });
  }
  /*
   * The offset between the html document height and the browser viewport
   * height will be greater than zero if vertical scroll is possible.
   * This is the distance the user can scroll
   */
  function getDistanceToScroll() {
    return $(document).height() - $(window).height();
  }

  function resizeProgressBar() {
    progressBar.css({ width: getWidthPercentage() + "%" });
  }
  // The scroll ratio equals the percentage to resize the bar
  function getWidthPercentage() {
    return (getCurrentScrollPosition() / getDistanceToScroll()) * 100;
  }
</script>

  </body>
</html>
